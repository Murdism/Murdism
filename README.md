# Murad Mebrahtu

**Autonomous Systems & Perception Engineer**  
Perception ‚Ä¢ Field Testing ‚Ä¢ ROS2 ‚Ä¢ Autonomous Vehicles

---

## About
I work on **perception systems and vehicle-level validation for autonomous vehicles**, with a strong focus on **LiDAR‚Äìcamera fusion**, **3D object detection**, and **trajectory prediction**. My work bridges **development, field testing, and deployment**, ensuring perception systems are reliable in real-world conditions.

I regularly work with **ROS2**, sensor calibration, ROS bag analysis, and simulation tools to validate perception outputs and support integration with autonomy stacks.

Currently at **Autonomous Vehicle‚Äôs Lab (AVLAB), Khalifa University**.

---

## What I Work On
- LiDAR‚Äìcamera **perception pipelines** for autonomous vehicles  
- **3D detection, tracking, and trajectory prediction** in ROS2  
- **Field testing & validation**: sensor calibration, data collection, debugging  
- **Simulation-based testing** using Gazebo and RViz  
- Real-time and **edge deployment** of perception models  

---

## Tech Stack
**Languages & Frameworks**  
- Python, C++  
- ROS2 (ROS1), PyTorch  

**Perception & Autonomy**  
- LiDAR & camera fusion  
- YOLO-based detection, tracking  
- Trajectory prediction  

**Tooling & Deployment**  
- Gazebo, RViz  
- TensorRT, Docker  
- Linux  

---

## Featured Project
**End-to-End Autonomous Vehicle Perception Pipeline**  
LiDAR‚Äìcamera perception system validated in **simulation and real-world field testing**, supporting detection, tracking, and prediction.

‚ñ∂Ô∏è Demo: https://www.youtube.com/watch?v=ZYhhkAWVly0

---

## Links
- üìÑ CV: https://murdism.github.io/resume/  
- üíº LinkedIn: https://linkedin.com/in/murad-s-mebrahtu-0311a0181  
- üåê Portfolio: https://murdism.github.io  
- üìß Email: muradsmebrahtu@gmail.com
